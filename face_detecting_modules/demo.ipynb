{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80faf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openmim>=0.2.1\n",
    "!mim install mmcv-full>=1.6.1\n",
    "!pip install mmdet>=2.25.1\n",
    "!pip install mmpose>=0.28.1\n",
    "!pip install -U moviepy>=1.0.3\n",
    "!git clone https://github.com/hysts/anime-face-detector\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OSpMJUNxiYx8",
   "metadata": {
    "id": "OSpMJUNxiYx8"
   },
   "source": [
    "If you encounter the following error in Colab, you can restart the runtime to execute the following cells correctly.\n",
    "\n",
    "```\n",
    "xtcocotools/_mask.pyx in init xtcocotools._mask()\n",
    "ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8DJZMVHhLIfI",
   "metadata": {
    "id": "8DJZMVHhLIfI"
   },
   "outputs": [],
   "source": [
    "%cd anime-face-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MlbQnEmE5wrj",
   "metadata": {
    "cellView": "form",
    "id": "MlbQnEmE5wrj"
   },
   "outputs": [],
   "source": [
    "#@title import packages\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import anime_face_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9UKeEAdHfvW",
   "metadata": {
    "cellView": "form",
    "id": "s9UKeEAdHfvW"
   },
   "outputs": [],
   "source": [
    "#@title Contour Definition\n",
    "\n",
    "# https://github.com/hysts/anime-face-detector/blob/main/assets/landmarks.jpg\n",
    "FACE_BOTTOM_OUTLINE = np.arange(0, 5)\n",
    "LEFT_EYEBROW = np.arange(5, 8)\n",
    "RIGHT_EYEBROW = np.arange(8, 11)\n",
    "LEFT_EYE_TOP = np.arange(11, 14)\n",
    "LEFT_EYE_BOTTOM = np.arange(14, 17)\n",
    "RIGHT_EYE_TOP = np.arange(17, 20)\n",
    "RIGHT_EYE_BOTTOM = np.arange(20, 23)\n",
    "NOSE = np.array([23])\n",
    "MOUTH_OUTLINE = np.arange(24, 28)\n",
    "\n",
    "FACE_OUTLINE_LIST = [FACE_BOTTOM_OUTLINE, LEFT_EYEBROW, RIGHT_EYEBROW]\n",
    "LEFT_EYE_LIST = [LEFT_EYE_TOP, LEFT_EYE_BOTTOM]\n",
    "RIGHT_EYE_LIST = [RIGHT_EYE_TOP, RIGHT_EYE_BOTTOM]\n",
    "NOSE_LIST = [NOSE]\n",
    "MOUTH_OUTLINE_LIST = [MOUTH_OUTLINE]\n",
    "\n",
    "# (indices, BGR color, is_closed)\n",
    "CONTOURS = [\n",
    "    (FACE_OUTLINE_LIST, (0, 170, 255), False),\n",
    "    (LEFT_EYE_LIST, (50, 220, 255), False),\n",
    "    (RIGHT_EYE_LIST, (50, 220, 255), False),\n",
    "    (NOSE_LIST, (255, 30, 30), False),\n",
    "    (MOUTH_OUTLINE_LIST, (255, 30, 30), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LO6BhPqtZSbi",
   "metadata": {
    "cellView": "form",
    "id": "LO6BhPqtZSbi"
   },
   "outputs": [],
   "source": [
    "#@title Visualization Function\n",
    "\n",
    "\n",
    "def visualize_box(image,\n",
    "                  box,\n",
    "                  score,\n",
    "                  lt,\n",
    "                  box_color=(0, 255, 0),\n",
    "                  text_color=(255, 255, 255),\n",
    "                  show_box_score=True):\n",
    "    cv2.rectangle(image, tuple(box[:2]), tuple(box[2:]), box_color, lt)\n",
    "    if not show_box_score:\n",
    "        return\n",
    "    cv2.putText(image,\n",
    "                f'{round(score * 100, 2)}%', (box[0], box[1] - 2),\n",
    "                0,\n",
    "                lt / 2,\n",
    "                text_color,\n",
    "                thickness=max(lt, 1),\n",
    "                lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def visualize_landmarks(image, pts, lt, landmark_score_threshold):\n",
    "    for *pt, score in pts:\n",
    "        pt = tuple(np.round(pt).astype(int))\n",
    "        if score < landmark_score_threshold:\n",
    "            color = (0, 255, 255)\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "        cv2.circle(image, pt, lt, color, cv2.FILLED)\n",
    "\n",
    "\n",
    "def draw_polyline(image, pts, color, closed, lt, skip_contour_with_low_score,\n",
    "                  score_threshold):\n",
    "    if skip_contour_with_low_score and (pts[:, 2] < score_threshold).any():\n",
    "        return\n",
    "    pts = np.round(pts[:, :2]).astype(int)\n",
    "    cv2.polylines(image, np.array([pts], dtype=np.int32), closed, color, lt)\n",
    "\n",
    "\n",
    "def visualize_contour(image, pts, lt, skip_contour_with_low_score,\n",
    "                      score_threshold):\n",
    "    for indices_list, color, closed in CONTOURS:\n",
    "        for indices in indices_list:\n",
    "            draw_polyline(image, pts[indices], color, closed, lt,\n",
    "                          skip_contour_with_low_score, score_threshold)\n",
    "\n",
    "\n",
    "def visualize(image: np.ndarray,\n",
    "              preds: np.ndarray,\n",
    "              face_score_threshold: float,\n",
    "              landmark_score_threshold: float,\n",
    "              show_box_score: bool = True,\n",
    "              draw_contour: bool = True,\n",
    "              skip_contour_with_low_score=False):\n",
    "    res = image.copy()\n",
    "\n",
    "    for pred in preds:\n",
    "        box = pred['bbox']\n",
    "        box, score = box[:4], box[4]\n",
    "        box = np.round(box).astype(int)\n",
    "        pred_pts = pred['keypoints']\n",
    "\n",
    "        # line_thickness\n",
    "        lt = max(2, int(3 * (box[2:] - box[:2]).max() / 256))\n",
    "\n",
    "        visualize_box(res, box, score, lt, show_box_score=show_box_score)\n",
    "        if draw_contour:\n",
    "            visualize_contour(\n",
    "                res,\n",
    "                pred_pts,\n",
    "                lt,\n",
    "                skip_contour_with_low_score=skip_contour_with_low_score,\n",
    "                score_threshold=landmark_score_threshold)\n",
    "        visualize_landmarks(res, pred_pts, lt, landmark_score_threshold)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2xLQJv-mB4",
   "metadata": {
    "cellView": "form",
    "id": "af2xLQJv-mB4"
   },
   "outputs": [],
   "source": [
    "#@title Detector\n",
    "\n",
    "device = 'cuda:0'  #@param ['cuda:0', 'cpu']\n",
    "model = 'yolov3'  #@param ['yolov3', 'faster-rcnn']\n",
    "detector = anime_face_detector.create_detector(model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zkcySBnkZsUZ",
   "metadata": {
    "cellView": "form",
    "id": "zkcySBnkZsUZ"
   },
   "outputs": [],
   "source": [
    "#@title Visualization Arguments\n",
    "\n",
    "face_score_threshold = 0.5  #@param {type: 'slider', min: 0, max: 1, step:0.1}\n",
    "landmark_score_threshold = 0.3  #@param {type: 'slider', min: 0, max: 1, step:0.1}\n",
    "show_box_score = True  #@param {'type': 'boolean'}\n",
    "draw_contour = True  #@param {'type': 'boolean'}\n",
    "skip_contour_with_low_score = True  #@param {'type': 'boolean'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EA46D11letIK",
   "metadata": {
    "id": "EA46D11letIK"
   },
   "source": [
    "# image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGsqDS9wBKsg",
   "metadata": {
    "id": "RGsqDS9wBKsg"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('assets/input.jpg')\n",
    "preds = detector(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yTUyNEKEZuVh",
   "metadata": {
    "id": "yTUyNEKEZuVh"
   },
   "outputs": [],
   "source": [
    "res = visualize(image, preds, face_score_threshold, landmark_score_threshold,\n",
    "                show_box_score, draw_contour, skip_contour_with_low_score)\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.imshow(res[:, :, ::-1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IVE9R_OgexgZ",
   "metadata": {
    "id": "IVE9R_OgexgZ"
   },
   "source": [
    "# video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ehGw6OyBBwXN",
   "metadata": {
    "id": "ehGw6OyBBwXN"
   },
   "outputs": [],
   "source": [
    "# https://www.sakugabooru.com/post/show/43401\n",
    "!wget -q https://www.sakugabooru.com/data/f47f699b9c5afc5a849be4b974f40975.mp4 -O input_vid.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n67jMIyQujHe",
   "metadata": {
    "id": "n67jMIyQujHe"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# skip frame\n",
    "speedx = 2\n",
    "clip = VideoFileClip('input_vid.mp4').subfx(lambda c: c.speedx(speedx))\n",
    "clip.write_videofile('input_vid_clip.mp4')\n",
    "clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xAumCV4WI7c8",
   "metadata": {
    "id": "xAumCV4WI7c8"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "cap = cv2.VideoCapture('input_vid_clip.mp4')\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_per_second = cap.get(cv2.CAP_PROP_FPS) / speedx\n",
    "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "writer = cv2.VideoWriter(\n",
    "    filename='/content/anime-face-detector/output_vid.mp4',\n",
    "    # some installation of opencv may not support x264 (due to its license),\n",
    "    # you can try other format (e.g. MPEG)\n",
    "    fourcc=cv2.VideoWriter_fourcc(*'MPEG'),\n",
    "    fps=frames_per_second,\n",
    "    frameSize=(width, height),\n",
    "    isColor=True)\n",
    "\n",
    "# Colab CPU 3.27s/it, Colab GPU 2.75it/s\n",
    "with tqdm(total=num_frames) as pbar:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        pbar.update()\n",
    "        preds = detector(frame)\n",
    "        vis_frame = visualize(\n",
    "            frame,\n",
    "            preds,\n",
    "            face_score_threshold=face_score_threshold,\n",
    "            landmark_score_threshold=landmark_score_threshold,\n",
    "            show_box_score=show_box_score,\n",
    "            draw_contour=draw_contour,\n",
    "            skip_contour_with_low_score=skip_contour_with_low_score)\n",
    "        writer.write(vis_frame)\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A_CgwlCLjkKd",
   "metadata": {
    "id": "A_CgwlCLjkKd"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i output_vid.mp4 -c:v libx264 -hide_banner -loglevel error -y out.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g2MLYVhWjiKz",
   "metadata": {
    "id": "g2MLYVhWjiKz"
   },
   "outputs": [],
   "source": [
    "from base64 import b64encode\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video height=400 controls loop>\n",
    "  <source src=\"data:video/mp4;base64,{b64encode(open('out.mp4','rb').read()).decode()}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SB5GeCbFjJMX",
   "metadata": {
    "id": "SB5GeCbFjJMX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hysts/anime-face-detector.ipynb",
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
